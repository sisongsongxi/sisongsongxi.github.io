
<!DOCTYPE html>
<html>
<head>
	<meta content="en-us" http-equiv="Content-Language">
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
	<title>Kaiming He</title>
	<meta charset="utf-8">
</head>
<body leftmargin="40" bgcolor="#FFFFFF" link="#444444" text="#444444">
	<table border="0" id="table1" width="720">
		<tbody>
			<tr>
				<td width="323">
					<p align="center"><font face="Arial"><img border="0" src="assets/images/csx.jpg" width="324" height="216"></font></p>
				</td>
				<td>
					<font face="Arial" size="5"><b>&nbsp;Sixi Cheng <span lang="zh-cn"> 成思希</span></b></font>
					<!-- <p><font face="Arial" style="font-size: 11pt;">&nbsp; Research Scientist</font></p>-->
					<p><font face="Arial" style="font-size: 11pt;">&nbsp; chengsixi.uestc.std.edu </font></p> 
				</td>
			</tr>
		</tbody>
	</table>
	<table border="1" style="border-width: 0px;" width="820">
		<tbody>
			<tr>
				<td style="border-style: none; border-width: medium;">
					<p style="margin-top: 3px; margin-bottom: 3px;"><font face="Arial" style="font-size: 11pt;">
						I will be joining the Department of Electrical Engineering and Computer Science (EECS) at Massachusetts Institute of Technology (MIT) as a faculty member in 2024.
						I am currently a Research Scientist at Facebook AI Research (FAIR).
						<br><br>
												
						My research covers a wide range of topics in computer vision and deep learning.
						Through the lens of computer vision problems, I aim to develop generalizable methods applicable to various domains.
						My research currently focuses on building computer models that can learn representations and develop intelligence from and for the complex world.
						The long-term goal of my research is to augment human intelligence with more capable artificial intelligence.
						<br><br>

						I have published a series of highly influential papers in computer vision and deep learning.
						My paper on Deep Residual Networks (ResNets) is the most cited paper in all research areas in Google Scholar Metrics for 2019, 2020, and 2021 and has established a fundamental component in modern deep learning models (e.g., in Transformers, AlphaGo Zero, AlphaFold).
						My works on visual object detection and segmentation, including Faster R-CNN and Mask R-CNN, have made significant impact and are among the most cited papers in these areas.
						My works on visual self-supervised learning are the top cited papers published in CVPR 2020, 2021, and 2022.
						My publications have over 460,000 citations (as of July 2023) with an increase of over 100,000 per year.
						<br><br>

						I am a recipient of several prestigious awards in the community, including the PAMI Young Researcher Award in 2018, the Best Paper Award in CVPR 2009, CVPR 2016, ICCV 2017, the Best Student Paper Award in ICCV 2017, the Best Paper Honorable Mention in ECCV 2018, CVPR 2021, and the Everingham Prize in ICCV 2021.
						<br><br>

						Before joining FAIR in 2016, I was a Researcher at Microsoft Research Asia (MSRA) from 2011 to 2016. I received my PhD degree from the Chinese University of Hong Kong in 2011, and my B.S. degree from Tsinghua University in 2007.
					</font></p>
				</td>
			</tr>
		</tbody>
	</table><br>
	<meta charset="utf-8">
	<p><b><font face="Arial" size="4">Publications</font></b></p>
	<p><span class="style8"><strong><font face="Arial"><a href="http://scholar.google.com/citations?user=DhtAFkwAAAAJ&amp;hl=en"><font color="#808080">Google Scholar Profile</font></a><br></font></strong></span></p>
	<table border="1" id="table2" style="border-width: 0px;" width="1154">
		<tbody>

			<tr>
				<td style="border-style: none; border-width: medium;" valign="top" width="19">&nbsp;</td>
				<td bgcolor="#FFCC99" style="border-style: none; border-width: medium;" valign="top" width="14">&nbsp;</td>
				<td style="border-style: none; border-width: medium;" valign="top" width="1108">
					<p style="margin-left: 10px; line-height: 150%; margin-top: 8px; margin-bottom: 8px;"><i><font face="Arial">Scaling Language-Image Pre-training via Masking</font></i><font face="Arial"><i><font style="font-size: 12pt;"><br></font></i></font>
						<font color="#000000" face="Arial" size="2">Yanghao Li<span>&#42;</span>, Haoqi Fan<span>&#42;</span>, Ronghang Hu<span>&#42;</span>, Christoph Feichtenhofer<sup>&dagger;</sup>, and <b>Kaiming He</b><sup>&dagger;</sup></font><b><font color="#000000" face="Arial" size="2"><br></font></b>
						<font face="Arial" size="2">Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023</font><br>
					<font face="Arial" size="2">
					<a href="https://arxiv.org/abs/2212.00794"><font color="#808080"><font color="#808080">arXiv</font></font></a>&nbsp;&nbsp;&nbsp;<b><a href="https://github.com/facebookresearch/flip"><font color="#808080" face="Arial" size="2">code</font></a></b>
				</td>
			</tr>

		</tbody>
	</table>

	<p><b><font face="Arial" size="4"><br>
		Activities</font></b></p>
		<ul>
			<li>
				<p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><font face="Arial" size="2"><b>Program Chair</b>: ICCV 2023</font></p>
			</li>
			<li>
				<p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><font face="Arial" size="2"><b>Senior Area Chair</b>: NeurIPS 2023</font></p>
			</li>
		</ul>
		<p></p>

	<p><b><font face="Arial" size="4"><br>Awards and Honors</font></b></p>
	<ul>
		<li>
			<p style="line-height: 150%; margin-left: 15px; margin-top: 0pt; margin-bottom: 0pt;"><b><font color="#444444" face="Arial" size="2"><font color="#444444" face="Arial" size="2"><b><a href="https://www.thecvf.com/?page_id=413#Everingham"><font color="#444444" face="Arial">PAMI Everingham Prize</font></a></b></font>, 2021</font></b></p>
		</li>
	</ul>
	<p><font size="2"><font size="2"><font size="2">&nbsp;<br>
	&nbsp; <a href="http://www.easycounter.com/"><img alt="HTML Counter" border="0" src="http://www.easycounter.com/counter.php?mingpurple"></a> <i><font face="Arial" size="2">unique visitors since May 2009</font></i></font></font></font></p>
</body>
</html>
